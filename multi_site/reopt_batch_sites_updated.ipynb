{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Site REopt API Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl as xl\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "\n",
    "import os\n",
    "from src.multi_site_inputs_parser import multi_site_csv_parser\n",
    "from src.parse_api_responses_to_csv import parse_responses_to_csv_with_template\n",
    "from src.post_and_poll import get_api_results\n",
    "from src.post_and_poll import get_run_uuid\n",
    "from src.parse_api_responses_to_excel import parse_api_responses_to_excel\n",
    "from src.results_poller import poller\n",
    "\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To-do: \n",
    "#### 1. Code currently uses secondary school ('Sec') load profile for community colleges ('Coll'). Remove relevant lines of code if/when Coll load profiles are included (lines are noted below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set today's date, choose input site file to run (from Patrick), and align output file name with input file (by date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input today's date.\n",
    "today_date = '2_24_22'\n",
    "\n",
    "#Align output file name with Patrick's sites file (label with same date as sites file).\n",
    "sites_file_name = 'reopt_in_sample_2022-02-09.csv'\n",
    "output_file_name = 'reopt_output_sample_2022-02-09'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set API key, server, and file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set API key and API server. (Yunus to replace with personal API key).\n",
    "API_KEY = 'n2HFzZ2FlTNJ6ADZsh7X3K4wxiBa4UvdMSgsmkEA'  \n",
    "server = 'https://developer.nrel.gov/api/reopt/v1'\n",
    "\n",
    "#Set number of seconds to wait between API post and get request.  \n",
    "interval = 10\n",
    "\n",
    "#Set path to input template, which will be filled in with site characteristics from Patrick's input file.   \n",
    "inputs_path = os.path.join('inputs')\n",
    "path_to_input_template = os.path.join(inputs_path, 'input_template.csv')\n",
    "\n",
    "#Set path to outputs folder.\n",
    "outputs_path = os.path.join('outputs')\n",
    "\n",
    "#Set path to input site file (from Patrick).\n",
    "sites_path = os.path.join('inputs/sites')\n",
    "path_to_sites = os.path.join(sites_path, sites_file_name)\n",
    "\n",
    "#Set path to utility rate lookup file.\n",
    "path_to_utility_rate = os.path.join(inputs_path, 'utility_rate_lookup_updated.csv')\n",
    "\n",
    "#Set path to file needed for battery size estimation.\n",
    "path_to_battery_size = os.path.join(inputs_path, 'ca_load_profile_cz_mo_20220111.csv')\n",
    "\n",
    "#Set path to load profiles file.\n",
    "load_profile_filename = 'LoadProfile_Type_CACZ_DOECZ.csv'\n",
    "path_to_load_profiles = os.path.join(inputs_path, 'load_profiles/'+load_profile_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate input file with site characteristics needed for REopt run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set non-site specific parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_values = {\n",
    "\n",
    "    #Patrick-derived values\n",
    "    'ElectricTariff|net_metering_limit_kw' : 1000,\n",
    "    'ElectricTariff|wholesale_rate_above_site_load_us_dollars_per_kwh' : 0.02,\n",
    "    'Financial|value_of_lost_load_us_dollars_per_kwh' : 0.58,\n",
    "    'Generator|diesel_fuel_cost_us_dollars_per_gallon' : 4,\n",
    "    'LoadProfile|outage_is_major_event' : 'FALSE',\n",
    "    'Storage|installed_cost_us_dollars_per_kw' : 840,\n",
    "    'Site|land_acres' : 0,\n",
    "\n",
    "    #REopt default values (commented out lines are intentionally left blank in input file / are covered by other inputs)\n",
    "    'ElectricTariff|add_blended_rates_to_urdb_rate' : 'FALSE',\n",
    "    'ElectricTariff|blended_annual_demand_charges_us_dollars_per_kw' : 0,\n",
    "    # 'ElectricTariff|blended_annual_rates_us_dollars_per_kwh' :,\n",
    "    # 'ElectricTariff|blended_monthly_demand_charges_us_dollars_per_kw' :,\n",
    "    # 'ElectricTariff|blended_monthly_rates_us_dollars_per_kwh' :,\n",
    "    'ElectricTariff|interconnection_limit_kw' : 100000000,\n",
    "    # 'ElectricTariff|urdb_rate_name' :,\n",
    "    # 'ElectricTariff|urdb_response' :,\n",
    "    'ElectricTariff|wholesale_rate_us_dollars_per_kwh' : 0, \n",
    "    'Financial|analysis_years' : 20,\n",
    "    'Financial|escalation_pct' : 0.026,\n",
    "    'Financial|microgrid_upgrade_cost_pct' : 0.3,\n",
    "    'Financial|offtaker_discount_pct' : 0.081,\n",
    "    'Financial|offtaker_tax_pct' : 0.26,\n",
    "    'Financial|om_cost_escalation_pct' : 0.025,\n",
    "    'Generator|existing_kw' : 0,\n",
    "    'Generator|federal_itc_pct' : 0,\n",
    "    'Generator|federal_rebate_us_dollars_per_kw' : 0, \n",
    "    'Generator|fuel_avail_gal' : 0,\n",
    "    'Generator|fuel_intercept_gal_per_hr' : 0, \n",
    "    'Generator|fuel_slope_gal_per_kwh' : 0,\n",
    "    'Generator|generator_only_runs_during_grid_outage' : 'TRUE',\n",
    "    'Generator|generator_sells_energy_back_to_grid' : 'FALSE',\n",
    "    'Generator|installed_cost_us_dollars_per_kw' : 2500,\n",
    "    'Generator|macrs_bonus_pct' : 0,\n",
    "    'Generator|macrs_itc_reduction' : 0, \n",
    "    'Generator|macrs_option_years' : 0,\n",
    "    'Generator|max_kw' : 1000000000,\n",
    "    'Generator|min_kw' : 0,\n",
    "    'Generator|min_turn_down_pct' : 0.3,\n",
    "    'Generator|om_cost_us_dollars_per_kw' : 50,\n",
    "    'Generator|om_cost_us_dollars_per_kwh' : 20,\n",
    "    'Generator|pbi_max_us_dollars' : 0,\n",
    "    'Generator|pbi_system_max_kw' : 0,\n",
    "    'Generator|pbi_us_dollars_per_kwh' : 0,\n",
    "    'Generator|pbi_years' : 0,\n",
    "    'Generator|state_ibi_max_us_dollars' : 0, \n",
    "    'Generator|state_ibi_pct' : 0,\n",
    "    'Generator|state_rebate_max_us_dollars' : 0,\n",
    "    'Generator|state_rebate_us_dollars_per_kw' : 0,\n",
    "    'Generator|utility_ibi_max_us_dollars' : 0,\n",
    "    'Generator|utility_ibi_pct' : 0,\n",
    "    'Generator|utility_rebate_max_us_dollars' : 0,\n",
    "    'Generator|utility_rebate_us_dollars_per_kw' : 0,\n",
    "    #'LoadProfile|critical_loads_kw' :,\n",
    "    'LoadProfile|critical_loads_kw_is_net' : 'FALSE',\n",
    "    #'LoadProfile|loads_kw' :,\n",
    "    'LoadProfile|loads_kw_is_net' : 'TRUE',\n",
    "    #'LoadProfile|monthly_totals_kwh' :,\n",
    "    'LoadProfile|year' : 2017,\n",
    "    'PV|array_type' : 1,\n",
    "    'PV|azimuth' : 180,\n",
    "    'PV|dc_ac_ratio' : 1.1,\n",
    "    'PV|degradation_pct' : 0.005,\n",
    "    'PV|existing_kw' : 0,\n",
    "    'PV|federal_itc_pct' : 0.3,\n",
    "    'PV|federal_rebate_us_dollars_per_kw' : 0,\n",
    "    'PV|gcr' : 0.4,\n",
    "    'PV|inv_eff' : 0.96,\n",
    "    'PV|losses' : 0.14,\n",
    "    'PV|macrs_bonus_pct' : 0,\n",
    "    'PV|macrs_itc_reduction' : 0.5,\n",
    "    'PV|macrs_option_years' : 5,\n",
    "    'PV|max_kw' : 1000000000,\n",
    "    'PV|min_kw' : 0,\n",
    "    'PV|module_type' : 0,\n",
    "    'PV|om_cost_us_dollars_per_kw' : 16,\n",
    "    'PV|pbi_max_us_dollars' : 1000000000,\n",
    "    'PV|pbi_system_max_kw' : 1000000000,\n",
    "    'PV|pbi_us_dollars_per_kwh' : 0,\n",
    "    'PV|pbi_years' : 1,\n",
    "    'PV|radius' : 0,\n",
    "    'PV|state_ibi_max_us_dollars' : 10000000000,\n",
    "    'PV|state_ibi_pct' : 0,\n",
    "    'PV|state_rebate_max_us_dollars' : 10000000000,\n",
    "    'PV|state_rebate_us_dollars_per_kw' : 0,\n",
    "    #PV|tilt :,\n",
    "    'PV|utility_ibi_max_us_dollars' : 10000000000,\n",
    "    'PV|utility_ibi_pct' : 0,\n",
    "    'PV|utility_rebate_max_us_dollars' : 10000000000,\n",
    "    'PV|utility_rebate_us_dollars_per_kw' : 0,\n",
    "    'Storage|battery_replacement_year' : 10,\n",
    "    'Storage|canGridCharge' : 'TRUE',\n",
    "    'Storage|internal_efficiency_pct' : 0.975,\n",
    "    'Storage|inverter_efficiency_pct' : 0.96,\n",
    "    'Storage|inverter_replacement_year' : 10,\n",
    "    'Storage|macrs_bonus_pct' : 0,\n",
    "    'Storage|macrs_itc_reduction' : 0.5,\n",
    "    'Storage|macrs_option_years' : 7,\n",
    "    'Storage|max_kw' : 1000000,\n",
    "    'Storage|max_kwh' : 1000000,\n",
    "    'Storage|min_kw' : 0,\n",
    "    'Storage|min_kwh' : 0,\n",
    "    'Storage|rectifier_efficiency_pct' : 0.96,\n",
    "    'Storage|replace_cost_us_dollars_per_kw' : 460,\n",
    "    'Storage|replace_cost_us_dollars_per_kwh' : 230,\n",
    "    'Storage|soc_init_pct' : 0.5,\n",
    "    'Storage|soc_min_pct' : 0.2,\n",
    "    'Storage|total_itc_pct' : 0,\n",
    "    'Storage|total_rebate_us_dollars_per_kw' : 0,\n",
    "    'time_steps_per_hour' : 1,\n",
    "    'timeout_seconds' : 295,\n",
    "    #user_uuid :\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use sites file, lookup tables, and load profiles file to populate input template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in sites file. Change name of utility column.\n",
    "sites = pd.read_csv(path_to_sites)\n",
    "sites.rename(columns={'utility':'utility_name_input_file'},inplace=True)\n",
    "\n",
    "#Read in input template to populate with site characteristics.\n",
    "input_template = pd.read_csv(path_to_input_template)\n",
    "\n",
    "#Read in lookup tables for utility rate and battery size.\n",
    "utility_rate = pd.read_csv(path_to_utility_rate)\n",
    "utility_rate.rename(columns={'utility_name_gis':'utility_name_input_file'}, inplace=True)\n",
    "\n",
    "battery_size = pd.read_csv(path_to_battery_size)\n",
    "\n",
    "#Read in load profiles csv.\n",
    "load_profiles = pd.read_csv(path_to_load_profiles)\n",
    "\n",
    "#Columns to pass from sites file to input_template.\n",
    "cols_to_pass = ['category', 'cz_cec_doe', 'city_ind', 'utility_name_input_file', 'Freq',\n",
    "       'roof_sqft.x', 'OID', 'latitude', 'longitude', 'roof_sqft.y',\n",
    "       'floor_sqft', 'diff', 'month', 'n', 'min_io', 'min_irr', 'max_p',\n",
    "       'max_punmet', 'num_floors', 'in_over_out_mo', 'clp_index', 'clp_name',\n",
    "       'clp_multiplier', 'critical_load_pct', 'dur_index', 'dur_name',\n",
    "       'dur_duration', 'roof_sqft']\n",
    "\n",
    "#Transfer site characteristics from sites file to input template (ex. roof_sqft)\n",
    "for col in cols_to_pass:\n",
    "    input_template[col] = sites[col]\n",
    "    \n",
    "#Fill in input template columns with non-site-specific parameter values set above.\n",
    "for col in input_template.columns:\n",
    "    if col in parameter_values.keys():\n",
    "        input_template[col] = parameter_values[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Remove the lines below if/when Community College load profiles are created.\n",
    "input_template['category_original']=input_template['category']\n",
    "input_template['category'] = input_template['category'].str.replace('Coll','Sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building category + climate zone = load profile code for lookup in load profile csv.\n",
    "input_template['load_profile_code'] = input_template['category'] + '_' + input_template['cz_cec_doe']\n",
    "input_template['load_file'] = load_profile_filename\n",
    "\n",
    "#Group input template by load profile code.\n",
    "grouped = input_template.groupby(['load_profile_code'])\n",
    "\n",
    "#Loop through load profile groups, getting the annual and peak load per sqft from load profile csv. Rejoin groups into one file.\n",
    "\n",
    "inputs = pd.DataFrame()\n",
    "for name, group in grouped:\n",
    "    \n",
    "    if name in load_profiles.columns:\n",
    "        max_kw_per_sqft = max(load_profiles[name])\n",
    "        group['max_kw_per_sqft'] = max_kw_per_sqft\n",
    "\n",
    "        annual_kwh_per_sqft = load_profiles[name].sum()\n",
    "        group['annual_kwh_per_sqft'] = annual_kwh_per_sqft\n",
    "\n",
    "        inputs = pd.concat([inputs, group],ignore_index=True)\n",
    "    else:\n",
    "        #Print load profile code if there's no match in load profile csv.\n",
    "        print(name)\n",
    "        \n",
    "#Scale annual and peak load by floor sqft.\n",
    "inputs['load_max_kw'] = inputs['max_kw_per_sqft']*inputs['floor_sqft']\n",
    "inputs['LoadProfile|annual_kwh'] = inputs['annual_kwh_per_sqft']*inputs['floor_sqft']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get URDB label (code for a specific utility rate) for each site based on utility name and building peak load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Match utility name from inputs file to utility name in URDB database.\n",
    "for row in inputs.index:\n",
    "    utility_name_input_file = inputs.loc[row,'utility_name_input_file']\n",
    "    utility_name_input_file_inds = utility_rate['utility_name_input_file']== utility_name_input_file \n",
    "    utility_name_urdb = utility_rate.loc[utility_name_input_file_inds, 'utility_name_urdb'].iloc[0]\n",
    "    inputs.loc[row, 'ElectricTariff|urdb_utility_name'] = utility_name_urdb\n",
    "    \n",
    "#Get URDB label based on utility name and max power. \n",
    "for row in inputs.index:\n",
    "    max_kw = inputs.loc[row,'load_max_kw']\n",
    "    utility = inputs.loc[row,'ElectricTariff|urdb_utility_name']\n",
    "    \n",
    "    utility_inds = utility_rate['utility_name_urdb'] == utility\n",
    "    \n",
    "    min_kw_inds = utility_rate['min_kw']<= max_kw\n",
    "    \n",
    "    max_kw_inds = utility_rate['max_kw']>= max_kw \n",
    "    nan_kw_inds = utility_rate['max_kw'].isna()\n",
    "    both_inds = max_kw_inds | nan_kw_inds\n",
    "    \n",
    "    filtered_utility_rate = utility_rate.loc[utility_inds & both_inds & min_kw_inds]\n",
    "    if filtered_utility_rate.empty:\n",
    "        filtered_utility_rate = utility_rate.loc[utility_inds & min_kw_inds].tail(1)\n",
    "    \n",
    "    urdb_label = filtered_utility_rate['urdb_label'].item()\n",
    "\n",
    "    inputs.loc[row, 'ElectricTariff|urdb_label'] = urdb_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate solar PV size based on roof sqft. Estimate solar cost based on solar PV size estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['Site|roof_squarefeet'] = inputs['roof_sqft']\n",
    "inputs['pv_kw_estimate'] = inputs['Site|roof_squarefeet']*14/1000/2\n",
    "inputs['PV|installed_cost_us_dollars_per_kw'] = 4000*(inputs['pv_kw_estimate']**(-0.10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set critical load pct, outage start times, and outage end times for each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['LoadProfile|critical_load_pct']=inputs['critical_load_pct']\n",
    "\n",
    "#Map month to outage start hour (first Tuesday of every month at 8am).\n",
    "month_to_outage_start_hour_dict = {\n",
    "    1:33, \n",
    "    2:873, \n",
    "    3:1545, \n",
    "    4:2217, \n",
    "    5:2889, \n",
    "    6:3729, \n",
    "    7:4401, \n",
    "    8:5241, \n",
    "    9:5913, \n",
    "    10:6585, \n",
    "    11:7425, \n",
    "    12:8097}\n",
    "\n",
    "#Determine outage end hour based on outage start hour and outage duration.\n",
    "inputs['LoadProfile|outage_start_hour']= inputs['month'].apply(lambda x:month_to_outage_start_hour_dict[x])\n",
    "inputs['LoadProfile|outage_end_hour']= inputs['LoadProfile|outage_start_hour']+inputs['dur_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set description to include key site characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get utility abbreviation to use for site description.\n",
    "def utility_abbrev(row):\n",
    "    return [s[0] for s in row['utility_name_input_file'].split()]\n",
    "\n",
    "abbrev_list = inputs.apply(utility_abbrev, axis=1)\n",
    "abbrev_list = [''.join(s) for s in abbrev_list]\n",
    "abbrev_list_col = pd.Series(abbrev_list)\n",
    "\n",
    "inputs['utility_abbrev'] = abbrev_list_col\n",
    "\n",
    "#Create site description column.\n",
    "def create_description(row):\n",
    "    return str(row['category_original']+'_'+row['cz_cec_doe']+'_'+row['utility_abbrev']+'_'+str(row['city_ind']) +'_c'+ str(row['LoadProfile|critical_load_pct'])+'_d'+str(row['dur_duration'])+'_s'+str(row['LoadProfile|outage_start_hour'])+'_r'+str(row['roof_sqft'])+'_f'+str(row['floor_sqft']))\n",
    "\n",
    "inputs['description'] = inputs.apply(create_description, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate battery size based on critical load fraction, outage duration, monthly avg power, and monthly avg irradiance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column that indiciates if critical load pct is > 0.5.\n",
    "clp_over_half_inds = inputs['critical_load_pct']>=0.5\n",
    "clp_under_half_inds = inputs['critical_load_pct']<0.5\n",
    "inputs.loc[clp_over_half_inds,'clp>0.5']='True'\n",
    "inputs.loc[clp_under_half_inds,'clp>0.5']='False'\n",
    "\n",
    "#Group sites by characteristics needed to estimate battery size.\n",
    "grouped_battery_size = inputs.groupby(['cz_cec_doe','category_original','month','clp>0.5'])\n",
    "\n",
    "#Loop through site groups, estimate battery size per sqft.\n",
    "\n",
    "inputs_with_battery_size = pd.DataFrame()\n",
    "\n",
    "for name, group in grouped_battery_size:\n",
    "    cz = name[0]\n",
    "    category = name[1]\n",
    "    month = name[2]\n",
    "    clp_over_half = name[3]\n",
    "    \n",
    "    cz_inds = battery_size['cz_cec_doe']== cz\n",
    "    category_inds = battery_size['category']== category\n",
    "    month_inds = battery_size['month']== month\n",
    "    \n",
    "    #Get first of these values in each group, since the values are the same in urban and rural areas (city_ind 0 or 1).\n",
    "    irr = battery_size[cz_inds & category_inds & month_inds]['Irr'].iloc[0]\n",
    "    power_avg = battery_size[cz_inds & category_inds & month_inds]['P_avg_per_floor_sqft'].iloc[0]\n",
    "    \n",
    "    #Use different equations for battery size if clp >= 0.5 vs <0.5.\n",
    "    if clp_over_half == 'False':\n",
    "        group['battery_size_kwh_per_sqft'] = 39.3*(group['critical_load_pct']**2)*power_avg + 0.185 * (group['critical_load_pct']**2) * power_avg * group['dur_duration'] - 3.67*10**(-6) * irr + 0.0251\n",
    "    elif clp_over_half == 'True':    \n",
    "        group['battery_size_kwh_per_sqft'] = 0.840 * (group['critical_load_pct']**2) * power_avg * group['dur_duration'] - 11.1*10**(-6) * irr + 0.073\n",
    "\n",
    "    inputs_with_battery_size = pd.concat([inputs_with_battery_size, group],ignore_index=True)\n",
    "    \n",
    "#Multiply battery size (kWh/floor sqft) by floor_sqft to get battery size estimate (kWh).\n",
    "inputs_with_battery_size['battery_size_kwh_estimate'] = inputs_with_battery_size['battery_size_kwh_per_sqft']*inputs_with_battery_size['floor_sqft']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate battery cost based on battery size estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate battery cost.\n",
    "inputs_with_battery_size['Storage|installed_cost_us_dollars_per_kwh'] = 1000*np.power(inputs_with_battery_size['battery_size_kwh_estimate'],(-0.19))\n",
    "\n",
    "#Set minimum battery cost to $120/kwh.\n",
    "inputs_with_battery_size.loc[inputs_with_battery_size['Storage|installed_cost_us_dollars_per_kwh']<120,'Storage|installed_cost_us_dollars_per_kwh'] = 120\n",
    "#Set maximum battery cost to $1000/kwh.\n",
    "inputs_with_battery_size.loc[inputs_with_battery_size['Storage|installed_cost_us_dollars_per_kwh']>1000,'Storage|installed_cost_us_dollars_per_kwh'] = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create site_id based on index of input file.\n",
    "inputs_with_battery_size['site_id']=inputs_with_battery_size.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove line below when coll load profiles are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_site_ids = inputs_with_battery_size[inputs_with_battery_size['category_original']=='Coll']['site_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_with_battery_size.to_csv('inputs/api_input_files/input_file_{}.csv'.format(today_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct posts for each site and send to REopt API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in input file saved in last step.\n",
    "path_to_api_inputs = 'inputs/api_input_files/input_file_{}.csv'.format(today_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform contents of input file to list of posts in the correct format for REopt API.\n",
    "list_of_posts = multi_site_csv_parser(path_to_api_inputs, api_url=server, API_KEY=API_KEY, start=0, n_sites=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folder (labeled with today's date) to store output files for each site. \n",
    "\n",
    "outputs_folder_name = 'outputs_' + today_date\n",
    "outputs_folder = os.path.join(outputs_path, outputs_folder_name)\n",
    "\n",
    "if not os.path.exists(outputs_folder):\n",
    "    os.makedirs(outputs_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main         INFO     Response OK from https://developer.nrel.gov/api/reopt/v1/job/?api_key=n2HFzZ2FlTNJ6ADZsh7X3K4wxiBa4UvdMSgsmkEA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_10_3B_SDG&E_1_c0.48742137_d96_s1545_r35200_f42200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main         INFO     Response OK from https://developer.nrel.gov/api/reopt/v1/job/?api_key=n2HFzZ2FlTNJ6ADZsh7X3K4wxiBa4UvdMSgsmkEA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_10_3B_SCE_1_c0.48742137_d96_s1545_r6000_f7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main         INFO     Response OK from https://developer.nrel.gov/api/reopt/v1/job/?api_key=n2HFzZ2FlTNJ6ADZsh7X3K4wxiBa4UvdMSgsmkEA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_10_3B_SDG&E_1_c1.299790321_d192_s1545_r11700_f14000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main         INFO     Response OK from https://developer.nrel.gov/api/reopt/v1/job/?api_key=n2HFzZ2FlTNJ6ADZsh7X3K4wxiBa4UvdMSgsmkEA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_10_3B_SCE_1_c0.64989516_d192_s1545_r6000_f7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main         INFO     Response OK from https://developer.nrel.gov/api/reopt/v1/job/?api_key=n2HFzZ2FlTNJ6ADZsh7X3K4wxiBa4UvdMSgsmkEA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_10_3B_SCE_0_c1.169811289_d96_s1545_r1200_f1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main         INFO     Response OK from https://developer.nrel.gov/api/reopt/v1/job/?api_key=n2HFzZ2FlTNJ6ADZsh7X3K4wxiBa4UvdMSgsmkEA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_10_3B_CoR_1_c0.9748427409999999_d48_s1545_r11700_f14000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main         INFO     Response OK from https://developer.nrel.gov/api/reopt/v1/job/?api_key=n2HFzZ2FlTNJ6ADZsh7X3K4wxiBa4UvdMSgsmkEA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_10_3B_SDG&E_1_c0.9748427409999999_d96_s1545_r11700_f14000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main         INFO     Response OK from https://developer.nrel.gov/api/reopt/v1/job/?api_key=n2HFzZ2FlTNJ6ADZsh7X3K4wxiBa4UvdMSgsmkEA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_10_3B_SDG&E_0_c0.9358490309999999_d48_s1545_r1200_f1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main         INFO     Response OK from https://developer.nrel.gov/api/reopt/v1/job/?api_key=n2HFzZ2FlTNJ6ADZsh7X3K4wxiBa4UvdMSgsmkEA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_10_3B_SDG&E_0_c1.559748385_d192_s1545_r11700_f11700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main         INFO     Response OK from https://developer.nrel.gov/api/reopt/v1/job/?api_key=n2HFzZ2FlTNJ6ADZsh7X3K4wxiBa4UvdMSgsmkEA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_10_3B_SCE_0_c0.584905644_d192_s1545_r118800_f118800\n"
     ]
    }
   ],
   "source": [
    "#Loop through list of posts, send posts to REopt API and store results.\n",
    "\n",
    "#responses = []\n",
    "\n",
    "break_ = False\n",
    "for post in list_of_posts:\n",
    "\n",
    "    #Post to REopt API and get run_uuid associated with that post.\n",
    "    run_id = get_run_uuid(post, API_KEY=API_KEY, api_url=server)\n",
    "\n",
    "    #Set name of results file to name of site.\n",
    "    site_name = post['Scenario']['description']\n",
    "    print(site_name)\n",
    "    site_file_name = site_name + '.json'\n",
    "    results_file = os.path.join(outputs_folder, site_file_name)\n",
    "\n",
    "    #Check for results from API using run_uuid from recent post. \n",
    "    finished = False\n",
    "    while not finished:\n",
    "        #Send get request to REopt to get results for the site.\n",
    "        url_results = server + '/job/{}/results/?api_key={}'.format(run_id , API_KEY)\n",
    "        get = requests.get(url=url_results, verify=False)\n",
    "        \n",
    "        results_output = json.loads(get.content)\n",
    "\n",
    "        status = results_output['outputs']['Scenario']['status']\n",
    "\n",
    "        if status != \"Optimizing...\":\n",
    "            finished = True\n",
    "        else:\n",
    "            time.sleep(interval)\n",
    "    \n",
    "    input_file = pd.read_csv(path_to_api_inputs)\n",
    "    \n",
    "    #Pass through the following site characteristics from the input sites file to the output file for each site. \n",
    "    \n",
    "    clp_multiplier = input_file.loc[input_file['description']==site_name]['clp_multiplier'].item()\n",
    "    results_output['inputs']['Scenario']['Site']['clp_multiplier']= clp_multiplier\n",
    "    \n",
    "    min_io = input_file.loc[input_file['description']==site_name]['min_io'].item()\n",
    "    results_output['inputs']['Scenario']['Site']['min_io']= min_io\n",
    "    \n",
    "    min_irr = input_file.loc[input_file['description']==site_name]['min_irr'].item()\n",
    "    results_output['inputs']['Scenario']['Site']['min_irr']= min_irr\n",
    "    \n",
    "    max_p = input_file.loc[input_file['description']==site_name]['max_p'].item()\n",
    "    results_output['inputs']['Scenario']['Site']['max_p']= max_p\n",
    "    \n",
    "    max_p_unmet = input_file.loc[input_file['description']==site_name]['max_p_unmet'].item()\n",
    "    results_output['inputs']['Scenario']['Site']['max_p_unmet']= max_p_unmet\n",
    "    \n",
    "    month = input_file.loc[input_file['description']==site_name]['month'].item()\n",
    "    results_output['inputs']['Scenario']['Site']['month']= float(month)\n",
    "    \n",
    "    floor_sqft = input_file.loc[input_file['description']==site_name]['floor_sqft'].item()\n",
    "    results_output['inputs']['Scenario']['Site']['floor_sqft']= float(floor_sqft)\n",
    "    \n",
    "    freq = input_file.loc[input_file['description']==site_name]['Freq'].item()\n",
    "    results_output['inputs']['Scenario']['Site']['freq']= float(freq)\n",
    "    \n",
    "    urban_rural = input_file.loc[input_file['description']==site_name]['city_ind'].item()\n",
    "    results_output['inputs']['Scenario']['Site']['city_ind']= float(urban_rural)\n",
    "    \n",
    "    category = input_file.loc[input_file['description']==site_name]['category_original'].item()\n",
    "    results_output['inputs']['Scenario']['Site']['category']= category\n",
    "    \n",
    "    utility = input_file.loc[input_file['description']==site_name]['utility_name_input_file'].item()\n",
    "    results_output['inputs']['Scenario']['Site']['utility']= utility\n",
    "    \n",
    "    cz = input_file.loc[input_file['description']==site_name]['cz_cec_doe'].item()\n",
    "    results_output['inputs']['Scenario']['Site']['cz_cec_doe']= cz\n",
    "\n",
    "    site_id = input_file.loc[input_file['description']==site_name]['site_id'].item()\n",
    "    results_output['inputs']['Scenario']['site_id']= site_id\n",
    "    \n",
    "    crit_load_pct = input_file.loc[input_file['description']==site_name]['critical_load_pct'].item()\n",
    "    results_output['inputs']['Scenario']['Site']['critical_load_pct']= crit_load_pct\n",
    "    \n",
    "    outage_dur = input_file.loc[input_file['description']==site_name]['dur_duration'].item()\n",
    "    results_output['inputs']['Scenario']['Site']['outage_duration']= outage_dur\n",
    "    \n",
    "    outage_start = input_file.loc[input_file['description']==site_name]['LoadProfile|outage_start_hour'].item()\n",
    "    results_output['inputs']['Scenario']['Site']['outage_start_hour']= outage_start\n",
    "    \n",
    "\n",
    "#Uncomment section below to run outage simulation (outage starting in every hour of the year) for each site:\n",
    "\n",
    "#     #Send post request to run outage simulation for site.\n",
    "#     post_text = {\"run_uuid\"= run_id, \"bau\"= True}\n",
    "#     url_outagesim = server + '/outagesimjob?API_KEY=' + API_KEY\n",
    "#     outagesim_post = requests.post(url_outagesim, json-post_text)\n",
    "\n",
    "#     #Send get request to resilience_stats endpoint, sleep for time interval if results aren't ready.\n",
    "#     finished = False\n",
    "#     while not finished:\n",
    "#         #Send get request for resilience stats for the site.\n",
    "#         url_resilience = server + '/job/{}/resilience_stats?API_KEY={}&bau=true'.format(run_id, API_KEY)\n",
    "#         resilience_output = json.loads(requests.get(url_resilience).content)\n",
    "\n",
    "#         for key in resilience_output:\n",
    "#             if key in ['Error']:\n",
    "#                 if resilience_output['Error'] == 'Outage sim results are not ready. If you have already submitted an outagesimjob, please try again later. If not, please first submit an outagesimjob by sending a POST request to v1/outagesimjob/ with run_uuid and bau parameters. This will generate outage simulation results that you can access from a GET request to the v1/job/<run uuid>/resilience_stats endpoint. Sample body data for POST-ing to /outagesimjob/= {\"run_uuid\"= \"6ea30f0f-3723-4fd1-8a3f-bebf8a3e4dbf\", \"bau\"= false}':  \n",
    "#                     time.sleep(interval)\n",
    "#                 else:\n",
    "#                     print('run_id=' + run_id)\n",
    "#                     print('count=' + str(count))\n",
    "#                     print(resilience_output)\n",
    "#                     finished = True\n",
    "#                     break_ = True\n",
    "#             else:\n",
    "#                 finished = True\n",
    "\n",
    "#     if break_ == True:\n",
    "#         break\n",
    "\n",
    "#     #Appends resilience output dictionary to results output dictionary.\n",
    "#     resilience_output_trim = dict(ele for sub in resilience_output.values() for ele in sub.items())\n",
    "#     results_output['outputs']['Scenario']['Site']['Resilience']=resilience_output_trim\n",
    "\n",
    "\n",
    "    #Write REopt results for the given site in the corresponding site output file.\n",
    "    with open(results_file, 'w') as fp:\n",
    "        json.dump(obj=results_output, fp=fp)\n",
    "\n",
    "    #Append site results to responses list to write all site results to Excel sheet in next step.\n",
    "    #responses.append(results_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write results to Excel file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through output files for each site (json files) and append contents to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'outputs' + '/outputs_' + today_date\n",
    "responses = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith('.json'):\n",
    "        filepath = 'outputs/' +'outputs_' + today_date + '/'+ str(filename)\n",
    "        f = open(filepath,'r')\n",
    "        contents = json.loads(f.read())\n",
    "        responses.append(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writes contents of list to Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/openpyxl/workbook/child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    }
   ],
   "source": [
    "parse_api_responses_to_excel(responses, spreadsheet='{}.xlsx'.format(output_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
